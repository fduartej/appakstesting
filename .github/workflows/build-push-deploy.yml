name: Build and Deploy Multi-Environment

on:
  push:
    branches:
      - main # ProducciÃ³n
      - develop # Desarrollo
      - qa # QA
      - uat # UAT
  workflow_dispatch:

env:
  DOTNET_VERSION: "9.0.x"
  IMAGE_NAME: database-test-api

jobs:
  # Job 1: Build una sola vez y genera imagen
  build:
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.vars.outputs.image-tag }}
      short-sha: ${{ steps.vars.outputs.short-sha }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set build variables
        id: vars
        run: |
          echo "image-tag=${{ github.sha }}" >> $GITHUB_OUTPUT
          echo "short-sha=${GITHUB_SHA:0:7}" >> $GITHUB_OUTPUT

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Build application
        run: dotnet build --configuration Release

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Login to Azure Container Registry
        uses: azure/docker-login@v1
        with:
          login-server: ${{ secrets.AZURE_ACR_SERVER }}
          username: ${{ secrets.AZURE_ACR_USERNAME }}
          password: ${{ secrets.AZURE_ACR_PASSWORD }}

      - name: Build and push Docker image
        run: |
          echo "ðŸ³ Building image with tag: ${{ steps.vars.outputs.image-tag }}"
          docker build -t ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:${{ steps.vars.outputs.image-tag }} .
          docker push ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:${{ steps.vars.outputs.image-tag }}

          # TambiÃ©n tag como latest para el branch correspondiente
          docker tag ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:${{ steps.vars.outputs.image-tag }} ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:latest
          docker push ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:latest

  # Job 2: Deploy a DEV usando Helm
  deploy-dev:
    if: github.ref == 'refs/heads/develop'
    needs: build
    runs-on: ubuntu-latest
    environment: dev
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "3.12.1"

      - name: Deploy with Helm template to DEV
        run: |
          echo "ðŸš€ Deploying to DEV environment with Helm template + kubectl"
          echo "ðŸ“¦ Image: ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:${{ needs.build.outputs.image-tag }}"
          echo "ðŸŒ Host: ${{ vars.INGRESS_HOST }}"
          echo "ðŸ·ï¸ Config Label: ${{ vars.AZURE_APP_CONFIG_LABEL }}"
          echo "ðŸ“ Namespace: ${{ vars.KUBERNETES_NAMESPACE }}"

          # Renderizar el chart en el runner
          helm template ${{ env.IMAGE_NAME }} ./k8s/chart \
            --namespace ${{ vars.KUBERNETES_NAMESPACE }} \
            --set image.repository=${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ needs.build.outputs.image-tag }} \
            --set ingress.host=${{ vars.INGRESS_HOST }} \
            --set environment=${{ vars.APP_ENVIRONMENT }} \
            --set appConfig.endpoint=${{ vars.AZURE_APP_CONFIG_ENDPOINT }} \
            --set appConfig.label=${{ vars.AZURE_APP_CONFIG_LABEL }} \
            --set workloadIdentity.clientId=${{ vars.AZURE_MANAGED_IDENTITY_CLIENT_ID }} \
            > manifest-dev.yaml

          echo "ðŸ“„ Manifest generado:"
          cat manifest-dev.yaml

          # Crear namespace si no existe
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get ns ${{ vars.KUBERNETES_NAMESPACE }} || kubectl create ns ${{ vars.KUBERNETES_NAMESPACE }}"

          # Aplicar el manifiesto en el cluster
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --file manifest-dev.yaml \
            --command "kubectl apply -f manifest-dev.yaml --namespace ${{ vars.KUBERNETES_NAMESPACE }} --validate=false"

      - name: Verify deployment in DEV
        run: |
          echo "âœ… Verificando deployment en DEV..."

          echo "ðŸ“Š Estado de deployment:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get deployment ${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

          echo "ðŸ“Š Estado de pods:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get pods -l app=${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

          echo "ðŸ“Š Estado de servicios:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get svc -n ${{ vars.KUBERNETES_NAMESPACE }}"

  # Job 3: Deploy a QA usando kubectl manifests
  deploy-qa:
    if: github.ref == 'refs/heads/qa'
    needs: build
    runs-on: ubuntu-latest
    environment: qa
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "3.12.1"

      - name: Deploy with Helm template to QA
        run: |
          echo "ðŸš€ Deploying to QA environment with Helm template + kubectl"
          echo "ðŸ“¦ Image: ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:${{ needs.build.outputs.image-tag }}"
          echo "ðŸŒ Host: ${{ vars.INGRESS_HOST }}"
          echo "ðŸ·ï¸ Config Label: ${{ vars.AZURE_APP_CONFIG_LABEL }}"
          echo "ðŸ“ Namespace: ${{ vars.KUBERNETES_NAMESPACE }}"

          # Renderizar el chart en el runner
          helm template ${{ env.IMAGE_NAME }} ./k8s/chart \
            --namespace ${{ vars.KUBERNETES_NAMESPACE }} \
            --set image.repository=${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ needs.build.outputs.image-tag }} \
            --set ingress.host=${{ vars.INGRESS_HOST }} \
            --set environment=${{ vars.APP_ENVIRONMENT }} \
            --set appConfig.endpoint=${{ vars.AZURE_APP_CONFIG_ENDPOINT }} \
            --set appConfig.label=${{ vars.AZURE_APP_CONFIG_LABEL }} \
            --set workloadIdentity.clientId=${{ vars.AZURE_MANAGED_IDENTITY_CLIENT_ID }} \
            > manifest-qa.yaml

          # Crear namespace si no existe
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get ns ${{ vars.KUBERNETES_NAMESPACE }} || kubectl create ns ${{ vars.KUBERNETES_NAMESPACE }}"

          # Aplicar el manifiesto en el cluster
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --file manifest-qa.yaml \
            --command "kubectl apply -f manifest-qa.yaml --namespace ${{ vars.KUBERNETES_NAMESPACE }} --validate=false"

      - name: Verify deployment in QA
        run: |
          echo "âœ… Verificando deployment en QA..."

          echo "ðŸ“Š Estado de deployment:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get deployment ${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

          echo "ðŸ“Š Estado de pods:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get pods -l app=${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

  # Job 4: Deploy a UAT usando kubectl manifests
  deploy-uat:
    if: github.ref == 'refs/heads/uat'
    needs: build
    runs-on: ubuntu-latest
    environment: uat
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "3.12.1"

      - name: Deploy with Helm template to UAT
        run: |
          echo "ðŸš€ Deploying to UAT environment with Helm template + kubectl"
          echo "ðŸ“¦ Image: ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:${{ needs.build.outputs.image-tag }}"
          echo "ðŸŒ Host: ${{ vars.INGRESS_HOST }}"
          echo "ðŸ·ï¸ Config Label: ${{ vars.AZURE_APP_CONFIG_LABEL }}"
          echo "ðŸ“ Namespace: ${{ vars.KUBERNETES_NAMESPACE }}"

          # Renderizar el chart en el runner
          helm template ${{ env.IMAGE_NAME }} ./k8s/chart \
            --namespace ${{ vars.KUBERNETES_NAMESPACE }} \
            --set image.repository=${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ needs.build.outputs.image-tag }} \
            --set ingress.host=${{ vars.INGRESS_HOST }} \
            --set environment=${{ vars.APP_ENVIRONMENT }} \
            --set appConfig.endpoint=${{ vars.AZURE_APP_CONFIG_ENDPOINT }} \
            --set appConfig.label=${{ vars.AZURE_APP_CONFIG_LABEL }} \
            --set workloadIdentity.clientId=${{ vars.AZURE_MANAGED_IDENTITY_CLIENT_ID }} \
            > manifest-uat.yaml

          # Crear namespace si no existe
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get ns ${{ vars.KUBERNETES_NAMESPACE }} || kubectl create ns ${{ vars.KUBERNETES_NAMESPACE }}"

          # Aplicar el manifiesto en el cluster
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --file manifest-uat.yaml \
            --command "kubectl apply -f manifest-uat.yaml --namespace ${{ vars.KUBERNETES_NAMESPACE }} --validate=false"

      - name: Verify deployment in UAT
        run: |
          echo "âœ… Verificando deployment en UAT..."

          echo "ðŸ“Š Estado de deployment:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get deployment ${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

          echo "ðŸ“Š Estado de pods:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get pods -l app=${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

  # Job 5: Deploy a PROD usando kubectl manifests
  deploy-prod:
    if: github.ref == 'refs/heads/main'
    needs: build
    runs-on: ubuntu-latest
    environment: prod
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "3.12.1"

      - name: Deploy with Helm template to PROD
        run: |
          echo "ðŸš€ Deploying to PROD environment with Helm template + kubectl"
          echo "ðŸ“¦ Image: ${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }}:${{ needs.build.outputs.image-tag }}"
          echo "ðŸŒ Host: ${{ vars.INGRESS_HOST }}"
          echo "ðŸ·ï¸ Config Label: ${{ vars.AZURE_APP_CONFIG_LABEL }}"
          echo "ðŸ“ Namespace: ${{ vars.KUBERNETES_NAMESPACE }}"

          # Renderizar el chart en el runner
          helm template ${{ env.IMAGE_NAME }} ./k8s/chart \
            --namespace ${{ vars.KUBERNETES_NAMESPACE }} \
            --set image.repository=${{ secrets.AZURE_ACR_SERVER }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ needs.build.outputs.image-tag }} \
            --set ingress.host=${{ vars.INGRESS_HOST }} \
            --set environment=${{ vars.APP_ENVIRONMENT }} \
            --set appConfig.endpoint=${{ vars.AZURE_APP_CONFIG_ENDPOINT }} \
            --set appConfig.label=${{ vars.AZURE_APP_CONFIG_LABEL }} \
            --set workloadIdentity.clientId=${{ vars.AZURE_MANAGED_IDENTITY_CLIENT_ID }} \
            > manifest-prod.yaml

          # Crear namespace si no existe
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get ns ${{ vars.KUBERNETES_NAMESPACE }} || kubectl create ns ${{ vars.KUBERNETES_NAMESPACE }}"

          # Aplicar el manifiesto en el cluster
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --file manifest-prod.yaml \
            --command "kubectl apply -f manifest-prod.yaml --namespace ${{ vars.KUBERNETES_NAMESPACE }} --validate=false"

      - name: Verify deployment in PROD
        run: |
          echo "âœ… Verificando deployment en PROD..."

          echo "ðŸ“Š Estado de deployment:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get deployment ${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

          echo "ðŸ“Š Estado de pods:"
          az aks command invoke \
            --resource-group ${{ vars.AZURE_RESOURCE_GROUP }} \
            --name ${{ vars.AZURE_AKS_CLUSTER }} \
            --command "kubectl get pods -l app=${{ env.IMAGE_NAME }} -n ${{ vars.KUBERNETES_NAMESPACE }} -o wide"

          echo "âœ… Production deployment completed successfully!"
